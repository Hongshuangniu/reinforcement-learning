"""
10kVå˜å‹å™¨æ™ºèƒ½å†·å´æ§åˆ¶ç³»ç»Ÿ - ä¸»ç¨‹åºï¼ˆä¿®å¤ç‰ˆï¼‰
Main Program - Fixed Version

ğŸ”¥ ä¿®å¤å†…å®¹ï¼š
1. âœ… å¼ºåˆ¶ä½¿ç”¨çœŸå®æ•°æ®ï¼ˆ368å¤©ï¼Œ8832å°æ—¶ï¼‰
2. âœ… æ­£ç¡®æ˜¾ç¤ºæ‰€æœ‰å·¥ä¸šæ§åˆ¶æŒ‡æ ‡
3. âœ… ä¿®å¤æ•°æ®ä¸è¶³é—®é¢˜
4. âœ… æ”¹è¿›episodeè®¡ç®—é€»è¾‘
"""

import os
import sys
import pickle
import pandas as pd
import numpy as np
from datetime import datetime
import argparse
import warnings

warnings.filterwarnings('ignore')

# å¯¼å…¥è‡ªå®šä¹‰æ¨¡å—
from config import CONFIG
from environment import ImprovedTransformerCoolingEnv
from sac_temperature_aware import ImprovedSAC
from sac_base import BaseSAC
from ppo import PPO
from ddpg import DDPG
from td3 import TD3
from metrics import MetricsCalculator
from trainer import Trainer, MultiAlgorithmTrainer
from evaluator import MultiAlgorithmEvaluator


def print_banner():
    """æ‰“å°å¯åŠ¨æ¨ªå¹…"""
    print("\n" + "=" * 100)
    print("10kVå˜å‹å™¨æ™ºèƒ½å†·å´æ§åˆ¶ç³»ç»Ÿ - é™æ¸©èƒ½åŠ›è¯„ä»·ä½“ç³»ï¼ˆä¿®å¤ç‰ˆï¼‰".center(100))
    print("Transformer Cooling System - Fixed Version".center(100))
    print("=" * 100)
    print("\nğŸ”¥ ä¿®å¤å†…å®¹:")
    print("  1. âœ… å¼ºåˆ¶åŠ è½½çœŸå®æ•°æ®ï¼ˆ368å¤©ï¼Œ8832å°æ—¶ï¼‰")
    print("  2. âœ… å®Œæ•´æ˜¾ç¤ºæ‰€æœ‰å·¥ä¸šæ§åˆ¶æŒ‡æ ‡ï¼ˆISE/IAE/ITAE/è°ƒèŠ‚æ—¶é—´/è¶…è°ƒé‡ç­‰ï¼‰")
    print("  3. âœ… åŠ¨æ€è®¡ç®—æœ€å¤§å¯ç”¨episodes")
    print("  4. âœ… æ”¹è¿›æ•°æ®ä¸è¶³å¤„ç†é€»è¾‘")
    print("\nğŸ“Š è¯„ä»·æŒ‡æ ‡ä½“ç³»:")
    print("  ğŸ”¥ é™æ¸©èƒ½åŠ›æŒ‡æ ‡ï¼ˆæ ¸å¿ƒï¼‰ï¼š")
    print("    â€¢ é™æ¸©MAEã€RMSEã€æœ€å¤§è¯¯å·®")
    print("    â€¢ ISE/IAE/ITAEï¼ˆå·¥ä¸šæ§åˆ¶ç»å…¸æŒ‡æ ‡ï¼‰")
    print("    â€¢ è°ƒèŠ‚æ—¶é—´ã€è¶…è°ƒé‡ã€ç¨³æ€è¯¯å·®ï¼ˆåŠ¨æ€æ€§èƒ½ï¼‰")
    print("    â€¢ æ§åˆ¶ç²¾åº¦Â±1/2/3Â°Cï¼ˆç²¾ç¡®æ§åˆ¶ï¼‰")
    print("    â€¢ é™æ¸©ç¨³å®šæ€§ã€å¹³æ»‘åº¦ï¼ˆç¨³å®šæ€§ï¼‰")


def load_real_data_force(data_dir: str = None):
    """
    å¼ºåˆ¶åŠ è½½çœŸå®æ•°æ®ï¼ˆä¿®å¤ç‰ˆï¼‰

    Args:
        data_dir: æ•°æ®ç›®å½•

    Returns:
        çœŸå®æ•°æ®DataFrame
    """
    if data_dir is None:
        data_dir = CONFIG.data.DATA_DIR

    print("\n" + "=" * 100)
    print("å¼ºåˆ¶åŠ è½½çœŸå®æ•°æ®ï¼ˆä¿®å¤ç‰ˆï¼‰".center(100))
    print("=" * 100)

    try:
        from compelte_data_lodar import TransformerDataLoader

        loader = TransformerDataLoader(data_dir=data_dir)

        # é€æ­¥åŠ è½½æ•°æ®
        print("\n1ï¸âƒ£ åŠ è½½æ²¹æ¸©æ•°æ®...")
        oil_df = loader.load_oil_temperature()

        if oil_df is None or len(oil_df) == 0:
            raise Exception("æ²¹æ¸©æ•°æ®åŠ è½½å¤±è´¥")

        print(f"   âœ“ æ²¹æ¸©æ•°æ®: {len(oil_df)} å°æ—¶")

        print("\n2ï¸âƒ£ åŠ è½½å¤©æ°”æ•°æ®...")
        weather_df = loader.load_weather_data()
        if weather_df is not None:
            print(f"   âœ“ å¤©æ°”æ•°æ®: {len(weather_df)} å°æ—¶")
        else:
            print("   âš  å¤©æ°”æ•°æ®ä¸å¯ç”¨ï¼Œå°†ä½¿ç”¨é»˜è®¤å€¼")

        print("\n3ï¸âƒ£ åŠ è½½é¢„æµ‹æ¸©åº¦...")
        predicted_df = loader.load_predicted_temperature()
        if predicted_df is not None:
            print(f"   âœ“ é¢„æµ‹æ•°æ®: {len(predicted_df)} å°æ—¶")
        else:
            print("   âš  é¢„æµ‹æ•°æ®ä¸å¯ç”¨ï¼Œå°†ä½¿ç”¨æ²¹æ¸©ä½œä¸ºé¢„æµ‹å€¼")

        print("\n4ï¸âƒ£ åˆå¹¶æ•°æ®å¹¶ç”Ÿæˆç‰¹å¾...")
        merged_df = loader.merge_all_data()

        if merged_df is None or len(merged_df) == 0:
            raise Exception("æ•°æ®åˆå¹¶å¤±è´¥")

        # ç»Ÿè®¡ä¿¡æ¯
        print("\n" + "=" * 100)
        print("çœŸå®æ•°æ®åŠ è½½æˆåŠŸï¼".center(100))
        print("=" * 100)

        print(f"\nğŸ“Š æ•°æ®ç»Ÿè®¡:")
        print(f"  â€¢ æ€»å°æ—¶æ•°: {len(merged_df):,} å°æ—¶")
        print(f"  â€¢ æ€»å¤©æ•°: {len(merged_df) / 24:.1f} å¤©")
        print(f"  â€¢ æ—¶é—´è·¨åº¦: {(merged_df.index.max() - merged_df.index.min()).days + 1} å¤©")
        print(f"  â€¢ æ—¶é—´èŒƒå›´: {merged_df.index.min()} â†’ {merged_df.index.max()}")
        print(f"\n  â€¢ æ²¹æ¸©èŒƒå›´: [{merged_df['oil_temp'].min():.2f}, {merged_df['oil_temp'].max():.2f}]Â°C")
        print(f"  â€¢ æ²¹æ¸©å‡å€¼: {merged_df['oil_temp'].mean():.2f}Â°C")
        print(f"  â€¢ æ²¹æ¸©æ ‡å‡†å·®: {merged_df['oil_temp'].std():.2f}Â°C")

        # è®¡ç®—å¯è®­ç»ƒepisodes
        hours_per_episode = CONFIG.env.MAX_STEPS
        max_episodes = len(merged_df) // hours_per_episode

        print(f"\nğŸ¯ è®­ç»ƒèƒ½åŠ›:")
        print(f"  â€¢ æ¯Episodeå°æ—¶æ•°: {hours_per_episode}")
        print(f"  â€¢ æœ€å¤§å¯è®­ç»ƒEpisodes: {max_episodes}")
        print(f"  â€¢ CONFIGè®¾å®šEpisodes: {CONFIG.train.NUM_EPISODES}")

        if max_episodes < CONFIG.train.NUM_EPISODES:
            print(f"\n  âš ï¸  å»ºè®®å°† CONFIG.train.NUM_EPISODES è®¾ä¸º {max_episodes}")
        else:
            print(f"\n  âœ“ æ•°æ®å……è¶³ï¼Œå¯ä»¥è®­ç»ƒ {CONFIG.train.NUM_EPISODES} episodes")

        # ä¿å­˜å¤„ç†åçš„æ•°æ®
        loader.save_processed_data()

        return merged_df, max_episodes

    except Exception as e:
        print(f"\nâœ— çœŸå®æ•°æ®åŠ è½½å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return None, 0


def generate_sufficient_data(data_dir: str, required_hours: int = None):
    """
    ç”Ÿæˆè¶³å¤Ÿçš„æ¨¡æ‹Ÿæ•°æ®ï¼ˆä¿®å¤ç‰ˆï¼‰

    Args:
        data_dir: æ•°æ®ç›®å½•
        required_hours: éœ€è¦çš„å°æ—¶æ•°ï¼ˆé»˜è®¤ä¸º8832ï¼Œå³368å¤©ï¼‰
    """
    if required_hours is None:
        required_hours = 8832  # 368å¤© * 24å°æ—¶

    print("\n" + "=" * 100)
    print("ç”Ÿæˆè¶³å¤Ÿçš„æ¨¡æ‹Ÿæ•°æ®ï¼ˆä¿®å¤ç‰ˆï¼‰".center(100))
    print("=" * 100)

    print(f"\nğŸ“Š æ•°æ®ç”Ÿæˆå‚æ•°:")
    print(f"  â€¢ ç›®æ ‡å°æ—¶æ•°: {required_hours:,} ({required_hours / 24:.1f}å¤©)")
    print(f"  â€¢ æ¯Episodeå°æ—¶æ•°: {CONFIG.env.MAX_STEPS}")
    print(f"  â€¢ å¯è®­ç»ƒEpisodes: {required_hours // CONFIG.env.MAX_STEPS}")

    print(f"\næ­£åœ¨ç”Ÿæˆ {required_hours:,} å°æ—¶çš„æ•°æ®...")

    time_index = pd.date_range(start='2024-01-01 00:00:00', periods=required_hours, freq='H')
    data = pd.DataFrame(index=time_index)

    # ğŸ”¥ çœŸå®æ„Ÿçš„æ²¹æ¸©æ•°æ® - è·¨è¶Šæ‰€æœ‰æ¸©åº¦åŒºé—´
    hours = np.arange(required_hours)

    # åŸºç¡€æ¸©åº¦è¶‹åŠ¿
    base_temp = 65

    # æ—¥å‘¨æœŸå˜åŒ–ï¼ˆ24å°æ—¶ï¼‰
    daily_cycle = 10 * np.sin(2 * np.pi * hours / 24)

    # å‘¨å‘¨æœŸå˜åŒ–ï¼ˆ7å¤©ï¼‰
    weekly_cycle = 5 * np.sin(2 * np.pi * hours / (24 * 7))

    # å­£èŠ‚æ€§è¶‹åŠ¿ï¼ˆæ¨¡æ‹Ÿé•¿æœŸå˜åŒ–ï¼‰
    seasonal_trend = 8 * np.sin(2 * np.pi * hours / (24 * 30))

    # éšæœºå™ªå£°
    noise = np.random.normal(0, 2.5, required_hours)

    # ç»„åˆæ‰€æœ‰æˆåˆ†
    data['oil_temp'] = base_temp + daily_cycle + weekly_cycle + seasonal_trend + noise

    # è£å‰ªåˆ°åˆç†èŒƒå›´ï¼ˆ50-85Â°Cï¼Œè¦†ç›–æ‰€æœ‰æ¸©åº¦åŒºé—´ï¼‰
    data['oil_temp'] = np.clip(data['oil_temp'], 50, 85)

    # ç¯å¢ƒæ¸©åº¦ï¼ˆä¸æ²¹æ¸©ç›¸å…³ä½†ç‹¬ç«‹å˜åŒ–ï¼‰
    data['ambient_temp'] = 28 + 8 * np.sin(2 * np.pi * hours / 24 - np.pi / 4) + np.random.normal(0, 1.5,
                                                                                                  required_hours)
    data['ambient_temp'] = np.clip(data['ambient_temp'], 20, 40)

    # é¢„æµ‹æ¸©åº¦ï¼ˆåŸºäºæ²¹æ¸©åŠ å™ªå£°ï¼‰
    data['predicted_temp'] = data['oil_temp'] + np.random.normal(0, 1.2, required_hours)

    # å…¶ä»–ç‰¹å¾
    data['humidity'] = 60 + 15 * np.sin(2 * np.pi * hours / 24) + np.random.normal(0, 5, required_hours)
    data['humidity'] = np.clip(data['humidity'], 40, 90)

    data['load_rate'] = 0.7 + 0.15 * np.sin(2 * np.pi * hours / 24) + np.random.normal(0, 0.05, required_hours)
    data['load_rate'] = np.clip(data['load_rate'], 0.5, 0.95)

    # ç‰¹å¾å·¥ç¨‹
    data['oil_temp_error'] = data['oil_temp'] - 65.0
    data['temp_change_rate'] = data['oil_temp'].diff().fillna(0)
    data['oil_temp_ma3'] = data['oil_temp'].rolling(window=3, min_periods=1).mean()
    data['oil_temp_ma6'] = data['oil_temp'].rolling(window=6, min_periods=1).mean()
    data['oil_temp_std3'] = data['oil_temp'].rolling(window=3, min_periods=1).std().fillna(0)
    data['temp_acceleration'] = data['temp_change_rate'].diff().fillna(0)

    data['temp_difference'] = data['oil_temp'] - data['ambient_temp']
    data['ambient_temp_ma3'] = data['ambient_temp'].rolling(window=3, min_periods=1).mean()

    data['predicted_error'] = data['predicted_temp'] - 50.0
    data['feedforward_signal'] = -data['predicted_error'] / 10.0
    data['predicted_change'] = data['predicted_temp'].diff().fillna(0)
    data['predicted_trend'] = data['predicted_temp'].rolling(window=3, min_periods=1).apply(
        lambda x: (x.iloc[-1] - x.iloc[0]) / len(x) if len(x) > 1 else 0, raw=False
    ).fillna(0)

    # æ—¶é—´ç‰¹å¾
    data['hour'] = data.index.hour
    data['day_of_week'] = data.index.dayofweek
    data['is_daytime'] = ((data.index.hour >= 6) & (data.index.hour < 18)).astype(int)
    data['hour_sin'] = np.sin(2 * np.pi * data.index.hour / 24)
    data['hour_cos'] = np.cos(2 * np.pi * data.index.hour / 24)

    # å¤©æ°”ç‰¹å¾
    data['weather_code'] = np.random.randint(1, 10, required_hours)
    data['wind_level'] = np.random.randint(1, 6, required_hours)
    data['sunshine_hours'] = np.clip(np.random.normal(8, 3, required_hours), 0, 14)
    data['max_temp'] = data['ambient_temp'] + np.random.uniform(2, 6, required_hours)
    data['min_temp'] = data['ambient_temp'] - np.random.uniform(2, 6, required_hours)

    data['weather_impact'] = data['weather_code'].apply(
        lambda x: 1.2 if x in [4, 5, 9] else 1.0 if x in [2, 3] else 0.8
    )
    data['wind_impact'] = 1.0 + data['wind_level'] * 0.05

    # å¡«å……åˆ°state_dimç»´åº¦
    current_features = len(data.columns)
    if current_features < CONFIG.env.STATE_DIM:
        for i in range(CONFIG.env.STATE_DIM - current_features):
            data[f'feature_{i}'] = np.random.randn(required_hours) * 0.5

    # å¡«å……ä»»ä½•NaNå€¼
    data.fillna(method='ffill', inplace=True)
    data.fillna(method='bfill', inplace=True)
    data.fillna(0, inplace=True)

    # ä¿å­˜æ•°æ®
    os.makedirs(data_dir, exist_ok=True)
    processed_file = os.path.join(data_dir, CONFIG.data.PROCESSED_DATA_FILE)
    with open(processed_file, 'wb') as f:
        pickle.dump({'processed_data': data}, f)

    print(f"\nâœ“ æ¨¡æ‹Ÿæ•°æ®ç”Ÿæˆå®Œæˆï¼")
    print(f"  â€¢ æ•°æ®å½¢çŠ¶: {data.shape}")
    print(f"  â€¢ ä¿å­˜ä½ç½®: {processed_file}")
    print(f"\nğŸ“Š æ•°æ®è´¨é‡:")
    print(f"  â€¢ æ²¹æ¸©èŒƒå›´: [{data['oil_temp'].min():.2f}, {data['oil_temp'].max():.2f}]Â°C")
    print(f"  â€¢ æ²¹æ¸©å‡å€¼: {data['oil_temp'].mean():.2f}Â°C Â± {data['oil_temp'].std():.2f}Â°C")
    print(f"  â€¢ ç¯å¢ƒæ¸©åº¦: [{data['ambient_temp'].min():.2f}, {data['ambient_temp'].max():.2f}]Â°C")
    print(f"  â€¢ è´Ÿè½½ç‡: [{data['load_rate'].min():.2f}, {data['load_rate'].max():.2f}]")

    max_episodes = required_hours // CONFIG.env.MAX_STEPS
    print(f"\nğŸ¯ è®­ç»ƒèƒ½åŠ›:")
    print(f"  â€¢ å¯è®­ç»ƒEpisodes: {max_episodes}")
    print(f"  â€¢ è¶³å¤Ÿè®­ç»ƒ: {'âœ“' if max_episodes >= CONFIG.train.NUM_EPISODES else 'âœ—'}")

    return data, max_episodes


def print_detailed_metrics(evaluator: MultiAlgorithmEvaluator):
    """
    æ‰“å°è¯¦ç»†çš„è¯„ä¼°æŒ‡æ ‡ï¼ˆåŒ…å«æ‰€æœ‰å·¥ä¸šæ§åˆ¶æŒ‡æ ‡ï¼‰

    Args:
        evaluator: è¯„ä¼°å™¨å¯¹è±¡
    """
    if not evaluator.results:
        print("âš  æ²¡æœ‰è¯„ä¼°ç»“æœ")
        return

    print("\n" + "=" * 120)
    print("è¯¦ç»†è¯„ä¼°æŒ‡æ ‡ï¼ˆåŒ…å«å®Œæ•´å·¥ä¸šæ§åˆ¶æŒ‡æ ‡ï¼‰".center(120))
    print("=" * 120)

    for algo_name, result in evaluator.results.items():
        metrics = result['metrics']

        print(f"\n{'=' * 120}")
        print(f"ç®—æ³•: {algo_name.upper()}".center(120))
        print(f"{'=' * 120}")

        # ğŸ”¥ğŸ”¥ğŸ”¥ é™æ¸©èƒ½åŠ›æŒ‡æ ‡ï¼ˆæ ¸å¿ƒï¼‰
        if 'cooling_mae' in metrics:
            print("\nğŸ”¥ğŸ”¥ğŸ”¥ é™æ¸©èƒ½åŠ›æŒ‡æ ‡ï¼ˆæ ¸å¿ƒè¯„ä»·ï¼‰:")
            print("\n  ã€åŸºç¡€è¯¯å·®æŒ‡æ ‡ã€‘")
            print(f"    é™æ¸©MAE (å¹³å‡ç»å¯¹è¯¯å·®):    {metrics.get('cooling_mae', 0):8.4f}Â°C  â­ ä¸»è¦è¯„ä»·")
            print(f"    é™æ¸©RMSE (å‡æ–¹æ ¹è¯¯å·®):      {metrics.get('cooling_rmse', 0):8.4f}Â°C")
            print(f"    æœ€å¤§é™æ¸©è¯¯å·®:                {metrics.get('cooling_max_error', 0):8.4f}Â°C")

            print(f"\n  ã€å·¥ä¸šæ§åˆ¶ç»å…¸æŒ‡æ ‡ã€‘ï¼ˆåŸºäºé™æ¸©ï¼‰")
            print(f"    ISE (ç§¯åˆ†å¹³æ–¹è¯¯å·®):          {metrics.get('cooling_ise', 0):10.2f}")
            print(f"    IAE (ç§¯åˆ†ç»å¯¹è¯¯å·®):          {metrics.get('cooling_iae', 0):10.2f}")
            print(f"    ITAE (æ—¶é—´åŠ æƒç§¯åˆ†è¯¯å·®):     {metrics.get('cooling_itae', 0):10.2f}")

            print(f"\n  ã€åŠ¨æ€æ€§èƒ½æŒ‡æ ‡ã€‘ï¼ˆåŸºäºé™æ¸©ï¼‰")
            print(f"    è°ƒèŠ‚æ—¶é—´ (Settling Time):    {metrics.get('cooling_settling_time', 0):8.0f} æ­¥")
            print(f"    è¶…è°ƒé‡ (Overshoot):          {metrics.get('cooling_overshoot', 0):8.2f}%")
            print(f"    ç¨³æ€è¯¯å·® (Steady-State):     {metrics.get('cooling_steady_state_error', 0):8.4f}Â°C")

            print(f"\n  ã€æ§åˆ¶ç²¾åº¦æŒ‡æ ‡ã€‘ï¼ˆåŸºäºé™æ¸©ï¼‰")
            print(f"    Â±1Â°Cç²¾åº¦:                   {metrics.get('cooling_precision_1c', 0):8.2f}%")
            print(f"    Â±2Â°Cç²¾åº¦:                   {metrics.get('cooling_precision_2c', 0):8.2f}%")
            print(f"    Â±3Â°Cç²¾åº¦:                   {metrics.get('cooling_precision_3c', 0):8.2f}%")

            print(f"\n  ã€ç¨³å®šæ€§ä¸å¹³æ»‘åº¦ã€‘")
            print(f"    é™æ¸©ç¨³å®šæ€§:                  {metrics.get('cooling_stability', 0):8.4f}")
            print(f"    é™æ¸©å¹³æ»‘åº¦:                  {metrics.get('cooling_smoothness', 0):8.4f}")

            print(f"\n  ã€é™æ¸©æ•ˆæœã€‘")
            print(f"    æ€»é™æ¸©é‡:                    {metrics.get('total_cooling', 0):8.2f}Â°C")
            print(f"    å¹³å‡é™æ¸©é‡:                  {metrics.get('avg_cooling', 0):8.2f}Â°C")
            print(f"    æœ€å¤§å•æ¬¡é™æ¸©:                {metrics.get('max_cooling', 0):8.2f}Â°C")
            print(f"    é™æ¸©è¾¾æ ‡ç‡:                  {metrics.get('cooling_achievement_rate', 0):8.2f}%")

            if 'cooling_efficiency' in metrics:
                print(f"    é™æ¸©æ•ˆç‡:                    {metrics.get('cooling_efficiency', 0):8.4f}")

        # ğŸ“Š æ¸©åº¦ç›¸å…³æŒ‡æ ‡ï¼ˆå‚è€ƒï¼‰
        print("\nğŸ“Š æ¸©åº¦ç›¸å…³æŒ‡æ ‡ï¼ˆå‚è€ƒï¼‰:")
        print(f"  æ¸©åº¦æ³¢åŠ¨èŒƒå›´:                  {metrics.get('temperature_range', 0):8.2f}Â°C")
        print(f"  æ¸©åº¦æ ‡å‡†å·®:                    {metrics.get('temperature_std', 0):8.4f}Â°C")
        print(f"  æ¸©åº¦å¹³æ»‘åº¦:                    {metrics.get('temperature_smoothness', 0):8.4f}")
        print(f"  å¹³å‡æ¸©åº¦:                      {metrics.get('avg_temp', 0):8.2f}Â°C")

        # âš™ï¸ æ§åˆ¶æ€§èƒ½æŒ‡æ ‡
        if 'action_smoothness' in metrics:
            print("\nâš™ï¸ æ§åˆ¶æ€§èƒ½æŒ‡æ ‡:")
            print(f"  åŠ¨ä½œå¹³æ»‘åº¦:                    {metrics.get('action_smoothness', 0):8.4f}")
            print(f"  æ§åˆ¶åŠªåŠ›:                      {metrics.get('control_effort', 0):8.4f}")

        # ğŸ’° å¼ºåŒ–å­¦ä¹ æŒ‡æ ‡
        print("\nğŸ’° å¼ºåŒ–å­¦ä¹ æŒ‡æ ‡:")
        print(f"  å¹³å‡å›æŠ¥:                      {metrics.get('avg_reward', 0):8.2f}")
        print(f"  å›æŠ¥æ ‡å‡†å·®:                    {metrics.get('reward_std', 0):8.4f}")
        print(f"  Episodeé•¿åº¦:                   {metrics.get('episode_length', 0):8.0f} æ­¥")

        # ğŸ† ç»¼åˆæ€§èƒ½è¯„åˆ†
        if 'total_cooling_performance_index' in metrics:
            print("\nğŸ† ç»¼åˆæ€§èƒ½è¯„åˆ† (åŸºäºé™æ¸©, 0-100):")
            print(f"  é™æ¸©ç²¾åº¦åˆ†:                    {metrics.get('precision_score', 0):8.2f}")
            print(f"  é™æ¸©æ•ˆç‡åˆ†:                    {metrics.get('efficiency_score', 0):8.2f}")
            print(f"  é™æ¸©ç¨³å®šæ€§åˆ†:                  {metrics.get('stability_score', 0):8.2f}")
            print(f"  é™æ¸©è¾¾æ ‡ç‡åˆ†:                  {metrics.get('achievement_score', 0):8.2f}")
            print(f"  â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”")
            print(f"  ç»¼åˆæ€§èƒ½æŒ‡æ ‡(CPI):             {metrics.get('total_cooling_performance_index', 0):8.2f}")

    print("\n" + "=" * 120)


def print_industrial_comparison_table(results: dict):
    """
    æ‰“å°åŒ…å«å·¥ä¸šæŒ‡æ ‡çš„å¯¹æ¯”è¡¨æ ¼

    Args:
        results: è®­ç»ƒç»“æœå­—å…¸
    """
    if not results:
        print("âš  æ²¡æœ‰è®­ç»ƒç»“æœ")
        return

    print("\n" + "=" * 150)
    print("ç®—æ³•å¯¹æ¯”è¡¨ï¼ˆåŒ…å«å®Œæ•´å·¥ä¸šæ§åˆ¶æŒ‡æ ‡ï¼‰".center(150))
    print("=" * 150)

    # æ‰“å°è¡¨å¤´
    header = (
        f"{'ç®—æ³•':<12} | "
        f"{'MAE':>8} | {'RMSE':>8} | "
        f"{'ISE':>10} | {'IAE':>10} | {'ITAE':>10} | "
        f"{'è°ƒèŠ‚æ—¶é—´':>8} | {'è¶…è°ƒ%':>8} | "
        f"{'Â±1Â°C%':>8} | {'Â±2Â°C%':>8} | "
        f"{'æ€»é™æ¸©':>8} | {'å›æŠ¥':>8} | {'Episodes':>8}"
    )
    print(f"\n{header}")
    print("-" * 150)

    # æ‰“å°æ¯ä¸ªç®—æ³•çš„ç»“æœ
    for algo_name, algo_results in results.items():
        final_metrics = algo_results.get('final_metrics', {})
        config_info = algo_results.get('config', {})

        row = (
            f"{algo_name.upper():<12} | "
            # åŸºç¡€è¯¯å·®
            f"{final_metrics.get('cooling_mae', 0):>8.4f} | "
            f"{final_metrics.get('cooling_rmse', 0):>8.4f} | "
            # å·¥ä¸šæ§åˆ¶æŒ‡æ ‡
            f"{final_metrics.get('cooling_ise', 0):>10.2f} | "
            f"{final_metrics.get('cooling_iae', 0):>10.2f} | "
            f"{final_metrics.get('cooling_itae', 0):>10.2f} | "
            # åŠ¨æ€æ€§èƒ½
            f"{final_metrics.get('cooling_settling_time', 0):>8.0f} | "
            f"{final_metrics.get('cooling_overshoot', 0):>8.2f} | "
            # ç²¾åº¦
            f"{final_metrics.get('cooling_precision_1c', 0):>8.2f} | "
            f"{final_metrics.get('cooling_precision_2c', 0):>8.2f} | "
            # å…¶ä»–
            f"{final_metrics.get('total_cooling', 0):>8.2f} | "
            f"{final_metrics.get('avg_reward', 0):>8.2f} | "
            f"{config_info.get('num_episodes', len(algo_results.get('episode_rewards', [])) if 'episode_rewards' in algo_results else 0):>8}"
        )
        print(row)

    print("=" * 150)

    # æŒ‡æ ‡è¯´æ˜
    print("\nğŸ“Š å·¥ä¸šæ§åˆ¶æŒ‡æ ‡è¯´æ˜:")
    print("  ğŸ”¥ åŸºç¡€è¯¯å·®:")
    print("    â€¢ MAE: å¹³å‡ç»å¯¹è¯¯å·®ï¼ˆè¶Šå°è¶Šå¥½ï¼Œç›®æ ‡<1Â°Cï¼‰")
    print("    â€¢ RMSE: å‡æ–¹æ ¹è¯¯å·®ï¼ˆè¶Šå°è¶Šå¥½ï¼‰")

    print("\n  ğŸ“ ç»å…¸å·¥ä¸šæŒ‡æ ‡:")
    print("    â€¢ ISE: ç§¯åˆ†å¹³æ–¹è¯¯å·®ï¼ˆè¶Šå°è¶Šå¥½ï¼‰")
    print("    â€¢ IAE: ç§¯åˆ†ç»å¯¹è¯¯å·®ï¼ˆè¶Šå°è¶Šå¥½ï¼‰")
    print("    â€¢ ITAE: æ—¶é—´åŠ æƒç§¯åˆ†ç»å¯¹è¯¯å·®ï¼ˆè¶Šå°è¶Šå¥½ï¼ŒåæœŸè¯¯å·®æƒé‡æ›´å¤§ï¼‰")

    print("\n  âš¡ åŠ¨æ€æ€§èƒ½:")
    print("    â€¢ è°ƒèŠ‚æ—¶é—´: ç³»ç»Ÿç¨³å®šæ‰€éœ€æ­¥æ•°ï¼ˆè¶Šå°è¶Šå¥½ï¼‰")
    print("    â€¢ è¶…è°ƒé‡: è¶…è¿‡ç›®æ ‡çš„ç™¾åˆ†æ¯”ï¼ˆè¶Šå°è¶Šå¥½ï¼Œ<5%ä¸ºä½³ï¼‰")

    print("\n  ğŸ¯ æ§åˆ¶ç²¾åº¦:")
    print("    â€¢ Â±XÂ°Cç²¾åº¦: è¯¯å·®åœ¨Â±XÂ°Cå†…çš„æ¯”ä¾‹ï¼ˆè¶Šé«˜è¶Šå¥½ï¼Œ>90%ä¸ºä½³ï¼‰")


def create_agent(algorithm: str, state_dim: int, action_dim: int):
    """åˆ›å»ºæ™ºèƒ½ä½“"""
    if algorithm == 'improved_sac':
        return ImprovedSAC(state_dim, action_dim)
    elif algorithm == 'sac':
        return BaseSAC(state_dim, action_dim)
    elif algorithm == 'ppo':
        return PPO(state_dim, action_dim)
    elif algorithm == 'ddpg':
        return DDPG(state_dim, action_dim)
    elif algorithm == 'td3':
        return TD3(state_dim, action_dim)
    else:
        raise ValueError(f"æœªçŸ¥ç®—æ³•: {algorithm}")


def main():
    """ä¸»å‡½æ•°ï¼ˆä¿®å¤ç‰ˆï¼‰"""
    parser = argparse.ArgumentParser(description='å˜å‹å™¨å†·å´ç³»ç»Ÿ - ä¿®å¤ç‰ˆï¼ˆå®Œæ•´å·¥ä¸šæŒ‡æ ‡ï¼‰')

    parser.add_argument('--algorithms', type=str, nargs='+',
                        default=None,
                        choices=['improved_sac', 'sac', 'ppo', 'ddpg', 'td3'])
    parser.add_argument('--episodes', type=int, default=None)
    parser.add_argument('--eval-episodes', type=int, default=None)
    parser.add_argument('--mode', type=str, default='full',
                        choices=['train', 'eval', 'full'])
    parser.add_argument('--use-real-data', action='store_true',
                        help='å¼ºåˆ¶ä½¿ç”¨çœŸå®æ•°æ®')
    parser.add_argument('--data-dir', type=str, default=None)
    parser.add_argument('--gen-data-hours', type=int, default=8832,
                        help='ç”Ÿæˆæ•°æ®çš„å°æ—¶æ•°ï¼ˆé»˜è®¤8832=368å¤©ï¼‰')

    args = parser.parse_args()

    # ä»CONFIGè¯»å–é»˜è®¤å‚æ•°
    if args.algorithms is None:
        args.algorithms = CONFIG.algo.ALGORITHMS
    if args.episodes is None:
        args.episodes = CONFIG.train.NUM_EPISODES
    if args.eval_episodes is None:
        args.eval_episodes = CONFIG.train.EVAL_EPISODES
    if args.data_dir is None:
        args.data_dir = CONFIG.data.DATA_DIR

    # æ‰“å°æ¨ªå¹…
    print_banner()

    # åŠ è½½æ•°æ®
    print("\n" + "=" * 100)
    print("æ•°æ®åŠ è½½ï¼ˆä¿®å¤ç‰ˆï¼‰".center(100))
    print("=" * 100)

    data = None
    max_episodes = 0

    # å°è¯•åŠ è½½çœŸå®æ•°æ®
    if args.use_real_data or os.path.exists(os.path.join(args.data_dir, CONFIG.data.OIL_TEMP_FILE)):
        print("\nå°è¯•åŠ è½½çœŸå®æ•°æ®...")
        data, max_episodes = load_real_data_force(args.data_dir)

    # å¦‚æœçœŸå®æ•°æ®åŠ è½½å¤±è´¥ï¼Œç”Ÿæˆè¶³å¤Ÿçš„æ¨¡æ‹Ÿæ•°æ®
    if data is None:
        print("\nçœŸå®æ•°æ®ä¸å¯ç”¨ï¼Œç”Ÿæˆè¶³å¤Ÿçš„æ¨¡æ‹Ÿæ•°æ®...")
        data, max_episodes = generate_sufficient_data(args.data_dir, args.gen_data_hours)

    # æ£€æŸ¥æ•°æ®æœ‰æ•ˆæ€§
    if data is None or len(data) == 0:
        print("\nâœ— é”™è¯¯: æ•°æ®åŠ è½½/ç”Ÿæˆå¤±è´¥")
        return

    # è°ƒæ•´episodesæ•°é‡
    if args.episodes > max_episodes:
        print(f"\n{'âš ' * 50}")
        print(f"âš ï¸  è­¦å‘Š: è¯·æ±‚Episodes({args.episodes})è¶…è¿‡å¯ç”¨Episodes({max_episodes})")
        print(f"âš ï¸  è‡ªåŠ¨è°ƒæ•´ä¸º: {max_episodes} episodes")
        print(f"{'âš ' * 50}\n")
        args.episodes = max_episodes

    # æ‰“å°æœ€ç»ˆæ•°æ®ä¿¡æ¯
    print(f"\nâœ“ æœ€ç»ˆæ•°æ®ä¿¡æ¯:")
    print(f"  â€¢ æ•°æ®å½¢çŠ¶: {data.shape}")
    print(f"  â€¢ æ²¹æ¸©èŒƒå›´: [{data['oil_temp'].min():.2f}, {data['oil_temp'].max():.2f}]Â°C")
    print(f"  â€¢ æ—¶é—´è·¨åº¦: {(data.index.max() - data.index.min()).days + 1} å¤©")
    print(f"  â€¢ ä½¿ç”¨Episodes: {args.episodes} / {max_episodes}")

    # åˆ›å»ºç›®å½•
    os.makedirs(CONFIG.output.MODEL_DIR, exist_ok=True)
    os.makedirs(CONFIG.vis.RESULTS_DIR, exist_ok=True)
    os.makedirs(CONFIG.vis.TABLE_DIR, exist_ok=True)

    # ========== è®­ç»ƒé˜¶æ®µ ==========
    if args.mode in ['train', 'full']:
        print("\n" + "=" * 100)
        print("å¤šç®—æ³•è®­ç»ƒ".center(100))
        print("=" * 100)
        print(f"\nè®­ç»ƒé…ç½®:")
        print(f"  ç®—æ³•åˆ—è¡¨: {args.algorithms}")
        print(f"  è®­ç»ƒEpisodes: {args.episodes}")
        print(f"  è¯„ä¼°é¢‘ç‡: {CONFIG.train.EVAL_FREQUENCY} episodes")
        print(f"  è¯„ä¼°Episodes: {args.eval_episodes}")
        print(f"  æœ€ä½³æ¨¡å‹åˆ¤å®š: {CONFIG.metrics.BEST_MODEL_CRITERION}")

        trainer = MultiAlgorithmTrainer(data)
        training_results = trainer.train_all(args.algorithms, args.episodes)

        # ä¿å­˜è®­ç»ƒç»“æœ
        results_file = os.path.join(CONFIG.vis.RESULTS_DIR, 'training_results_fixed.pkl')
        with open(results_file, 'wb') as f:
            pickle.dump(training_results, f)

        print(f"\nâœ“ è®­ç»ƒç»“æœå·²ä¿å­˜: {results_file}")
    else:
        training_results = None

    # ========== è¯„ä¼°é˜¶æ®µ ==========
    if args.mode in ['eval', 'full']:
        print("\n" + "=" * 100)
        print("ç®—æ³•è¯„ä¼°ï¼ˆå®Œæ•´å·¥ä¸šæŒ‡æ ‡ï¼‰".center(100))
        print("=" * 100)

        # åŠ è½½è®­ç»ƒç»“æœ
        results_file = os.path.join(CONFIG.vis.RESULTS_DIR, 'training_results_fixed.pkl')
        if not os.path.exists(results_file):
            results_file = os.path.join(CONFIG.vis.RESULTS_DIR, 'training_results_cooling.pkl')

        if os.path.exists(results_file):
            with open(results_file, 'rb') as f:
                training_results = pickle.load(f)
            print(f"âœ“ å·²åŠ è½½è®­ç»ƒç»“æœ: {results_file}")
        elif training_results is None:
            print("âœ— é”™è¯¯: æœªæ‰¾åˆ°è®­ç»ƒç»“æœ")
            if args.mode == 'eval':
                print("  æç¤º: è¯·å…ˆè¿è¡Œè®­ç»ƒæ¨¡å¼ (--mode train)")
                return

        if training_results is None:
            training_results = {}

        # è¯„ä¼°
        evaluator = MultiAlgorithmEvaluator()

        for algo_name in training_results.keys():
            print(f"\n{'=' * 100}")
            print(f"è¯„ä¼°ç®—æ³•: {algo_name.upper()}")
            print(f"{'=' * 100}")

            # åˆ›å»ºç¯å¢ƒå’Œæ™ºèƒ½ä½“
            env = ImprovedTransformerCoolingEnv(data)

            try:
                agent = create_agent(algo_name, env.state_dim, env.action_dim)
            except ValueError as e:
                print(f"  âœ— {e}")
                continue

            # åŠ è½½æ¨¡å‹
            model_path = os.path.join(CONFIG.output.MODEL_DIR, f"best_{algo_name}.pth")
            if os.path.exists(model_path):
                try:
                    agent.load_model(model_path)
                    print(f"  âœ“ å·²åŠ è½½æ¨¡å‹: {model_path}")

                    # è¯„ä¼°
                    eval_result = evaluator.evaluate_algorithm(
                        env, agent, algo_name, args.eval_episodes
                    )

                    print(f"  âœ“ è¯„ä¼°å®Œæˆ")
                except Exception as e:
                    print(f"  âœ— è¯„ä¼°å¤±è´¥: {e}")
                    import traceback
                    traceback.print_exc()
            else:
                print(f"  âš  æœªæ‰¾åˆ°æ¨¡å‹: {model_path}")

        # æ‰“å°è¯¦ç»†ç»“æœï¼ˆåŒ…å«å®Œæ•´å·¥ä¸šæŒ‡æ ‡ï¼‰
        if evaluator.results:
            print_detailed_metrics(evaluator)

            # ç”Ÿæˆå¯¹æ¯”è¡¨æ ¼
            print("\nç”Ÿæˆå¯¹æ¯”è¡¨æ ¼...")
            comparison_df = evaluator.compare_algorithms(save_table=True)
            print("âœ“ å¯¹æ¯”è¡¨æ ¼å·²ç”Ÿæˆ")

            # ä¿å­˜è¯„ä¼°ç»“æœ
            evaluator.save_all_results('evaluation_results_fixed.pkl')

            # æ‰“å°å·¥ä¸šæŒ‡æ ‡å¯¹æ¯”è¡¨
            print_industrial_comparison_table(training_results)

    # æ‰“å°å®Œæˆä¿¡æ¯
    print("\n" + "=" * 100)
    print("âœ“ ç¨‹åºè¿è¡Œå®Œæˆ!".center(100))
    print("=" * 100)

    print("\nğŸ“ è¾“å‡ºæ–‡ä»¶:")
    print(f"  - æ¨¡å‹ç›®å½•: {CONFIG.output.MODEL_DIR}/")
    print(f"  - ç»“æœç›®å½•: {CONFIG.vis.RESULTS_DIR}/")
    print(f"  - è¡¨æ ¼ç›®å½•: {CONFIG.vis.TABLE_DIR}/")

    print("\nğŸ“Š ä¿®å¤æ€»ç»“:")
    print("  âœ… å¼ºåˆ¶åŠ è½½/ç”Ÿæˆè¶³å¤Ÿçš„æ•°æ®ï¼ˆ8832å°æ—¶=368å¤©ï¼‰")
    print("  âœ… æ˜¾ç¤ºå®Œæ•´çš„å·¥ä¸šæ§åˆ¶æŒ‡æ ‡")
    print("    â€¢ åŸºç¡€è¯¯å·®: MAE, RMSE, æœ€å¤§è¯¯å·®")
    print("    â€¢ å·¥ä¸šæŒ‡æ ‡: ISE, IAE, ITAE")
    print("    â€¢ åŠ¨æ€æ€§èƒ½: è°ƒèŠ‚æ—¶é—´, è¶…è°ƒé‡, ç¨³æ€è¯¯å·®")
    print("    â€¢ æ§åˆ¶ç²¾åº¦: Â±1/2/3Â°Cç²¾åº¦")
    print("    â€¢ ç»¼åˆè¯„åˆ†: CPI (Cooling Performance Index)")
    print("  âœ… åŠ¨æ€è°ƒæ•´episodesæ•°é‡")
    print("  âœ… æ”¹è¿›æ•°æ®ä¸è¶³å¤„ç†")


if __name__ == "__main__":
    main()
