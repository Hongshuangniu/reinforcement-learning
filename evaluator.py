"""
10kVå˜å‹å™¨æ™ºèƒ½å†·å´æ§åˆ¶ç³»ç»Ÿ - è¯„ä¼°æ¨¡å—ï¼ˆå®Œæ•´ä¿®å¤ç‰ˆï¼‰
ä¿®å¤æŒ‡æ ‡è®¡ç®—é€»è¾‘ï¼Œç¡®ä¿å‡†ç¡®è¯„ä¼°
"""

import numpy as np
import pandas as pd
from typing import Dict, List, Optional
import os
import pickle

from environment import ImprovedTransformerCoolingEnv
from config import CONFIG


class ControlMetricsCalculator:
    """æ§åˆ¶æ€§èƒ½æŒ‡æ ‡è®¡ç®—å™¨ï¼ˆç‹¬ç«‹ç‰ˆæœ¬ï¼‰"""

    @staticmethod
    def calculate_temperature_control_metrics(
            temperatures: np.ndarray,
            target_temp: float = 50.0,
            tolerance: float = 2.0
    ) -> Dict[str, float]:
        """
        è®¡ç®—æ¸©åº¦æ§åˆ¶æ€§èƒ½æŒ‡æ ‡

        Args:
            temperatures: æ§åˆ¶åçš„æ¸©åº¦åºåˆ—
            target_temp: ç›®æ ‡æ¸©åº¦
            tolerance: å…è®¸åå·®èŒƒå›´

        Returns:
            æŒ‡æ ‡å­—å…¸
        """
        # è®¡ç®—æ¸©åº¦åå·®
        temp_errors = temperatures - target_temp
        abs_errors = np.abs(temp_errors)

        # åŸºç¡€ç»Ÿè®¡æŒ‡æ ‡
        mae = np.mean(abs_errors)  # å¹³å‡ç»å¯¹è¯¯å·®
        rmse = np.sqrt(np.mean(temp_errors ** 2))  # å‡æ–¹æ ¹è¯¯å·®
        max_ae = np.max(abs_errors)  # æœ€å¤§ç»å¯¹è¯¯å·®

        # ç›¸å¯¹è¯¯å·®ï¼ˆMAPEï¼‰- å¯¹äºæ¸©åº¦æ§åˆ¶ï¼Œç”¨åå·®å ç›®æ ‡æ¸©åº¦çš„æ¯”ä¾‹
        mape = np.mean(abs_errors / target_temp) * 100

        # æ¸©åº¦è¾¾æ ‡ç‡ï¼ˆåœ¨å…è®¸èŒƒå›´å†…çš„æ¯”ä¾‹ï¼‰
        in_range_ratio = np.mean(abs_errors <= tolerance) * 100

        # æ¸©åº¦ç¨³å®šæ€§æŒ‡æ ‡
        temp_std = np.std(temperatures)  # æ ‡å‡†å·®
        temp_range = np.ptp(temperatures)  # æå·®

        # è¶…è°ƒæŒ‡æ ‡
        overshoot_ratio = np.mean(temperatures > (target_temp + tolerance)) * 100
        undershoot_ratio = np.mean(temperatures < (target_temp - tolerance)) * 100

        # æ¸©åº¦å˜åŒ–å¹³æ»‘åº¦ï¼ˆè¿ç»­æ—¶åˆ»çš„æ¸©åº¦å˜åŒ–ï¼‰
        if len(temperatures) > 1:
            temp_changes = np.abs(np.diff(temperatures))
            temp_smoothness = np.mean(temp_changes)  # å¹³å‡æ¸©åº¦å˜åŒ–ç‡
        else:
            temp_smoothness = 0.0

        return {
            'MAE': mae,
            'RMSE': rmse,
            'MAPE': mape,
            'MaxAE': max_ae,
            'temp_in_range_ratio': in_range_ratio,
            'temp_std': temp_std,
            'temp_range': temp_range,
            'overshoot_ratio': overshoot_ratio,
            'undershoot_ratio': undershoot_ratio,
            'temp_smoothness': temp_smoothness,
            'avg_temp': np.mean(temperatures),
            'max_temp': np.max(temperatures),
            'min_temp': np.min(temperatures)
        }

    @staticmethod
    def calculate_reward_metrics(rewards: List[float]) -> Dict[str, float]:
        """
        è®¡ç®—å¼ºåŒ–å­¦ä¹ å›æŠ¥æŒ‡æ ‡

        Args:
            rewards: å›æŠ¥åºåˆ—

        Returns:
            æŒ‡æ ‡å­—å…¸
        """
        rewards_arr = np.array(rewards)

        # åŸºç¡€ç»Ÿè®¡
        total_reward = np.sum(rewards_arr)
        avg_reward = np.mean(rewards_arr)
        reward_std = np.std(rewards_arr)
        reward_variance = np.var(rewards_arr)

        # æ”¶æ•›æ€§åˆ†æï¼ˆå50%çš„å¹³å‡å›æŠ¥ï¼‰
        mid_point = len(rewards_arr) // 2
        if mid_point > 0:
            late_avg_reward = np.mean(rewards_arr[mid_point:])
        else:
            late_avg_reward = avg_reward

        # ç¨³å®šæ€§åˆ†æï¼ˆå50%çš„æ ‡å‡†å·®ï¼‰
        if mid_point > 0:
            late_reward_std = np.std(rewards_arr[mid_point:])
        else:
            late_reward_std = reward_std

        return {
            'total_reward': total_reward,
            'avg_reward': avg_reward,
            'reward_std': reward_std,
            'reward_variance': reward_variance,
            'late_avg_reward': late_avg_reward,
            'late_reward_std': late_reward_std,
            'max_reward': np.max(rewards_arr),
            'min_reward': np.min(rewards_arr)
        }

    @staticmethod
    def calculate_action_metrics(actions: np.ndarray) -> Dict[str, float]:
        """
        è®¡ç®—åŠ¨ä½œæ€§èƒ½æŒ‡æ ‡

        Args:
            actions: åŠ¨ä½œåºåˆ— (N, action_dim)

        Returns:
            æŒ‡æ ‡å­—å…¸
        """
        if len(actions) <= 1:
            return {
                'action_smoothness': 0.0,
                'action_std': 0.0
            }

        # åŠ¨ä½œå¹³æ»‘åº¦ï¼ˆè¿ç»­åŠ¨ä½œçš„å˜åŒ–ï¼‰
        action_changes = np.abs(np.diff(actions, axis=0))
        action_smoothness = np.mean(action_changes)

        # åŠ¨ä½œæ ‡å‡†å·®ï¼ˆæ¯ä¸ªç»´åº¦ï¼‰
        action_std = np.mean(np.std(actions, axis=0))

        return {
            'action_smoothness': action_smoothness,
            'action_std': action_std
        }


class Evaluator:
    """è¯„ä¼°å™¨ï¼ˆå®Œæ•´ä¿®å¤ç‰ˆï¼‰"""

    def __init__(self, env: ImprovedTransformerCoolingEnv, agent, algorithm_name: str):
        self.env = env
        self.agent = agent
        self.algorithm_name = algorithm_name
        self.metrics_calc = ControlMetricsCalculator()

    def evaluate_episode(self, deterministic: bool = True) -> Dict:
        """
        è¯„ä¼°ä¸€ä¸ªepisode

        Args:
            deterministic: æ˜¯å¦ä½¿ç”¨ç¡®å®šæ€§ç­–ç•¥

        Returns:
            episodeæ•°æ®å­—å…¸ï¼ˆåŒ…å«æ‰€æœ‰æŒ‡æ ‡ï¼‰
        """
        state = self.env.reset()

        temperatures = []  # å®é™…æ¸©åº¦åºåˆ—
        rewards = []
        actions = []
        log_probs = []

        done = False
        step = 0

        while not done:
            # é€‰æ‹©åŠ¨ä½œ
            if self.algorithm_name == 'ppo':
                action, log_prob, _ = self.agent.select_action(state, evaluate=deterministic)
                log_probs.append(log_prob)
            else:
                action = self.agent.select_action(state, evaluate=deterministic)
                log_probs.append(0.0)

            # æ‰§è¡ŒåŠ¨ä½œ
            next_state, reward, done, info = self.env.step(action)

            # æ”¶é›†æ•°æ®
            temperatures.append(info['oil_temp'])  # å½“å‰æ²¹æ¸©
            rewards.append(reward)
            actions.append(action.copy())

            state = next_state
            step += 1

        # è½¬æ¢ä¸ºnumpyæ•°ç»„
        temperatures = np.array(temperatures)
        actions = np.array(actions)
        log_probs = np.array(log_probs)

        # â­ è®¡ç®—æ¸©åº¦æ§åˆ¶æŒ‡æ ‡
        temp_metrics = self.metrics_calc.calculate_temperature_control_metrics(
            temperatures=temperatures,
            target_temp=CONFIG.env.TARGET_TEMP,
            tolerance=CONFIG.env.TEMP_TOLERANCE
        )

        # â­ è®¡ç®—å›æŠ¥æŒ‡æ ‡
        reward_metrics = self.metrics_calc.calculate_reward_metrics(rewards)

        # â­ è®¡ç®—åŠ¨ä½œæŒ‡æ ‡
        action_metrics = self.metrics_calc.calculate_action_metrics(actions)

        # åˆå¹¶æ‰€æœ‰æŒ‡æ ‡
        all_metrics = {**temp_metrics, **reward_metrics, **action_metrics}

        return {
            'temperatures': temperatures,
            'rewards': rewards,
            'actions': actions,
            'log_probs': log_probs,
            'metrics': all_metrics,
            'total_reward': sum(rewards),
            'avg_temp': np.mean(temperatures),
            'max_temp': np.max(temperatures),
            'min_temp': np.min(temperatures),
            'steps': step
        }

    def evaluate_multiple_episodes(self, num_episodes: int = 10, verbose: bool = True) -> Dict:
        """
        è¯„ä¼°å¤šä¸ªepisodes

        Args:
            num_episodes: è¯„ä¼°episodeæ•°é‡
            verbose: æ˜¯å¦æ‰“å°è¿›åº¦

        Returns:
            æ±‡æ€»ç»“æœ
        """
        all_episodes = []
        all_metrics = []

        for i in range(num_episodes):
            episode_data = self.evaluate_episode()
            all_episodes.append(episode_data)
            all_metrics.append(episode_data['metrics'])

            if verbose and (i + 1) % 5 == 0:
                print(f"  è¯„ä¼°è¿›åº¦: {i + 1}/{num_episodes} episodes")

        # è®¡ç®—æ‰€æœ‰æŒ‡æ ‡çš„å¹³å‡å€¼å’Œæ ‡å‡†å·®
        metrics_summary = {}
        for key in all_metrics[0].keys():
            values = [m[key] for m in all_metrics]
            metrics_summary[key] = np.mean(values)
            metrics_summary[f'{key}_std'] = np.std(values)

        # æ±‡æ€»ç»Ÿè®¡
        summary = {
            'avg_reward': np.mean([ep['total_reward'] for ep in all_episodes]),
            'std_reward': np.std([ep['total_reward'] for ep in all_episodes]),
            'avg_temp': np.mean([ep['avg_temp'] for ep in all_episodes]),
            'max_temp': np.max([ep['max_temp'] for ep in all_episodes]),
            'min_temp': np.min([ep['min_temp'] for ep in all_episodes]),
            'episodes': all_episodes,
            'metrics': metrics_summary
        }

        return summary


class MultiAlgorithmEvaluator:
    """å¤šç®—æ³•è¯„ä¼°å™¨"""

    def __init__(self):
        self.results = {}

    def evaluate_algorithm(
            self,
            env: ImprovedTransformerCoolingEnv,
            agent,
            algorithm_name: str,
            num_episodes: int = 10
    ) -> Dict:
        """
        è¯„ä¼°å•ä¸ªç®—æ³•

        Args:
            env: ç¯å¢ƒ
            agent: æ™ºèƒ½ä½“
            algorithm_name: ç®—æ³•åç§°
            num_episodes: è¯„ä¼°episodeæ•°é‡

        Returns:
            è¯„ä¼°ç»“æœ
        """
        print(f"\nğŸ” è¯„ä¼°ç®—æ³•: {algorithm_name.upper()}")
        evaluator = Evaluator(env, agent, algorithm_name)

        # è¯„ä¼°å¤šä¸ªepisodes
        summary = evaluator.evaluate_multiple_episodes(num_episodes)

        # ä¿å­˜ç»“æœ
        result = {
            'algorithm': algorithm_name,
            'summary': summary,
            'metrics': summary['metrics'],
            'all_episodes': summary['episodes']
        }

        self.results[algorithm_name] = result

        # æ‰“å°å…³é”®æŒ‡æ ‡
        m = summary['metrics']
        print(f"  âœ“ MAE: {m['MAE']:.2f}Â°C | RMSE: {m['RMSE']:.2f}Â°C | "
              f"è¾¾æ ‡ç‡: {m['temp_in_range_ratio']:.1f}% | "
              f"å¹³å‡å›æŠ¥: {m['avg_reward']:.1f}")

        return result

    def compare_algorithms(self, save_table: bool = True) -> pd.DataFrame:
        """
        å¯¹æ¯”æ‰€æœ‰ç®—æ³•

        Args:
            save_table: æ˜¯å¦ä¿å­˜è¡¨æ ¼

        Returns:
            å¯¹æ¯”è¡¨æ ¼
        """
        if not self.results:
            raise ValueError("No evaluation results available.")

        comparison_data = []
        for algo_name, result in self.results.items():
            metrics = result['metrics']

            row = {
                'Algorithm': algo_name.upper().replace('_', ' '),
                'MAE (Â°C)': metrics['MAE'],
                'RMSE (Â°C)': metrics['RMSE'],
                'MAPE (%)': metrics['MAPE'],
                'MaxAE (Â°C)': metrics['MaxAE'],
                'Temp In Range (%)': metrics['temp_in_range_ratio'],
                'Temp Std (Â°C)': metrics['temp_std'],
                'Overshoot (%)': metrics['overshoot_ratio'],
                'Avg Reward': metrics['avg_reward'],
                'Reward Std': metrics['reward_std'],
                'Action Smoothness': metrics['action_smoothness']
            }

            comparison_data.append(row)

        df = pd.DataFrame(comparison_data)

        if save_table:
            self.save_comparison_table(df)

        return df

    def save_comparison_table(self, df: pd.DataFrame, filename: str = 'algorithm_comparison.csv'):
        """ä¿å­˜å¯¹æ¯”è¡¨æ ¼"""
        os.makedirs(CONFIG.vis.TABLE_DIR, exist_ok=True)
        filepath = os.path.join(CONFIG.vis.TABLE_DIR, filename)
        df.to_csv(filepath, index=False, float_format='%.4f')
        print(f"\nâœ“ å¯¹æ¯”è¡¨æ ¼å·²ä¿å­˜åˆ°: {filepath}")

    def print_detailed_results(self):
        """æ‰“å°è¯¦ç»†ç»“æœ"""
        print("\n" + "=" * 90)
        print("è¯¦ç»†è¯„ä¼°ç»“æœ".center(90))
        print("=" * 90)

        for algo_name, result in self.results.items():
            print(f"\nç®—æ³•: {algo_name.upper()}")
            print("-" * 90)

            metrics = result['metrics']

            # æ¸©åº¦æ§åˆ¶æ€§èƒ½
            print("\nğŸ“Š æ¸©åº¦æ§åˆ¶æ€§èƒ½:")
            print(f"  å¹³å‡æ¸©åº¦åå·® (MAE):        {metrics['MAE']:.4f} Â°C")
            print(f"  å‡æ–¹æ ¹åå·® (RMSE):         {metrics['RMSE']:.4f} Â°C")
            print(f"  ç›¸å¯¹è¯¯å·® (MAPE):          {metrics['MAPE']:.2f} %")
            print(f"  æœ€å¤§åå·® (MaxAE):         {metrics['MaxAE']:.4f} Â°C")
            print(f"  æ¸©åº¦è¾¾æ ‡ç‡:                {metrics['temp_in_range_ratio']:.2f} %")
            print(f"  æ¸©åº¦æ ‡å‡†å·®:                {metrics['temp_std']:.4f} Â°C")
            print(f"  è¶…è°ƒæ¯”ä¾‹:                  {metrics['overshoot_ratio']:.2f} %")
            print(f"  æ¬ è°ƒæ¯”ä¾‹:                  {metrics['undershoot_ratio']:.2f} %")
            print(f"  æ¸©åº¦å¹³æ»‘åº¦:                {metrics['temp_smoothness']:.4f} Â°C/step")

            # æ§åˆ¶æ•ˆæœç»Ÿè®¡
            print("\nğŸ“ˆ æ§åˆ¶æ•ˆæœç»Ÿè®¡:")
            print(f"  å¹³å‡æ¸©åº¦:                  {metrics['avg_temp']:.2f} Â°C")
            print(f"  æ¸©åº¦èŒƒå›´:                  [{metrics['min_temp']:.2f}, {metrics['max_temp']:.2f}] Â°C")
            print(f"  æ¸©åº¦æå·®:                  {metrics['temp_range']:.2f} Â°C")

            # å¼ºåŒ–å­¦ä¹ æ€§èƒ½
            print("\nğŸ¯ å¼ºåŒ–å­¦ä¹ æ€§èƒ½:")
            print(f"  å¹³å‡å›æŠ¥:                  {metrics['avg_reward']:.2f}")
            print(f"  å›æŠ¥æ ‡å‡†å·®:                {metrics['reward_std']:.4f}")
            print(f"  åæœŸå¹³å‡å›æŠ¥:              {metrics['late_avg_reward']:.2f}")
            print(f"  åæœŸå›æŠ¥æ ‡å‡†å·®:            {metrics['late_reward_std']:.4f}")

            # åŠ¨ä½œæ€§èƒ½
            print("\nğŸ® åŠ¨ä½œæ€§èƒ½:")
            print(f"  åŠ¨ä½œå¹³æ»‘åº¦:                {metrics['action_smoothness']:.4f}")
            print(f"  åŠ¨ä½œæ ‡å‡†å·®:                {metrics['action_std']:.4f}")

    def save_all_results(self, filename: str = 'evaluation_results.pkl'):
        """ä¿å­˜æ‰€æœ‰è¯„ä¼°ç»“æœ"""
        os.makedirs(CONFIG.vis.RESULTS_DIR, exist_ok=True)
        filepath = os.path.join(CONFIG.vis.RESULTS_DIR, filename)
        with open(filepath, 'wb') as f:
            pickle.dump(self.results, f)
        print(f"âœ“ è¯„ä¼°ç»“æœå·²ä¿å­˜åˆ°: {filepath}")

    def load_all_results(self, filename: str = 'evaluation_results.pkl'):
        """åŠ è½½è¯„ä¼°ç»“æœ"""
        filepath = os.path.join(CONFIG.vis.RESULTS_DIR, filename)
        with open(filepath, 'rb') as f:
            self.results = pickle.load(f)
        print(f"âœ“ è¯„ä¼°ç»“æœå·²åŠ è½½: {filepath}")


def generate_evaluation_csv_files(results: Dict, save_dir: str = 'results'):
    """ç”Ÿæˆè¯„ä¼°ç›¸å…³çš„CSVæ–‡ä»¶"""
    os.makedirs(save_dir, exist_ok=True)

    for algo_name, algo_results in results.items():
        episodes = algo_results['all_episodes']

        for ep_idx, episode in enumerate(episodes[:3]):
            # æ¸©åº¦æ§åˆ¶CSV
            temp_df = pd.DataFrame({
                'step': range(len(episode['temperatures'])),
                'temperature': episode['temperatures'],
                'target_temp': CONFIG.env.TARGET_TEMP,
                'upper_bound': CONFIG.env.TARGET_TEMP + CONFIG.env.TEMP_TOLERANCE,
                'lower_bound': CONFIG.env.TARGET_TEMP - CONFIG.env.TEMP_TOLERANCE
            })
            temp_df.to_csv(
                os.path.join(save_dir, f'{algo_name}_temperature_control_ep{ep_idx}.csv'),
                index=False
            )

            # æ§åˆ¶åŠ¨ä½œCSV
            action_df = pd.DataFrame(
                episode['actions'],
                columns=['pressure', 'peltier', 'valve_opening']
            )
            action_df['step'] = range(len(action_df))
            action_df.to_csv(
                os.path.join(save_dir, f'{algo_name}_control_action_ep{ep_idx}.csv'),
                index=False
            )

        print(f"âœ“ {algo_name} è¯„ä¼°CSVæ–‡ä»¶å·²ç”Ÿæˆ")


def generate_metrics_table(results: Dict, save_dir: str = 'tables'):
    """ç”ŸæˆæŒ‡æ ‡å¯¹æ¯”è¡¨æ ¼"""
    os.makedirs(save_dir, exist_ok=True)

    # æ§åˆ¶æ€§èƒ½æŒ‡æ ‡è¡¨
    control_data = []
    for algo_name, algo_results in results.items():
        m = algo_results['metrics']
        control_data.append({
            'Algorithm': algo_name.upper().replace('_', ' '),
            'MAE (Â°C)': m['MAE'],
            'RMSE (Â°C)': m['RMSE'],
            'MAPE (%)': m['MAPE'],
            'MaxAE (Â°C)': m['MaxAE'],
            'Temp In Range (%)': m['temp_in_range_ratio'],
            'Temp Std (Â°C)': m['temp_std'],
            'Overshoot (%)': m['overshoot_ratio']
        })

    control_df = pd.DataFrame(control_data)
    control_df.to_csv(
        os.path.join(save_dir, 'control_performance_metrics.csv'),
        index=False,
        float_format='%.4f'
    )

    # RLæ€§èƒ½æŒ‡æ ‡è¡¨
    rl_data = []
    for algo_name, algo_results in results.items():
        m = algo_results['metrics']
        rl_data.append({
            'Algorithm': algo_name.upper().replace('_', ' '),
            'Avg Reward': m['avg_reward'],
            'Reward Std': m['reward_std'],
            'Late Avg Reward': m['late_avg_reward'],
            'Action Smoothness': m['action_smoothness']
        })

    rl_df = pd.DataFrame(rl_data)
    rl_df.to_csv(
        os.path.join(save_dir, 'rl_performance_metrics.csv'),
        index=False,
        float_format='%.4f'
    )

    print(f"âœ“ æŒ‡æ ‡è¡¨æ ¼å·²ä¿å­˜åˆ°: {save_dir}")


if __name__ == "__main__":
    print("=" * 70)
    print("è¯„ä¼°æ¨¡å—æµ‹è¯•ï¼ˆå®Œæ•´ä¿®å¤ç‰ˆï¼‰".center(70))
    print("=" * 70)

    print("\nâœ… å…³é”®æ”¹è¿›:")
    print("  1. âœ… ç§»é™¤å¯¹ä¸å­˜åœ¨çš„ 'predicted_temp' çš„ä¾èµ–")
    print("  2. âœ… ç›´æ¥è®¡ç®—æ¸©åº¦ä¸ç›®æ ‡æ¸©åº¦(50Â°C)çš„åå·®")
    print("  3. âœ… ç‹¬ç«‹å®ç°æŒ‡æ ‡è®¡ç®—å™¨ï¼Œé¿å…ä¾èµ–å¤–éƒ¨æ¨¡å—")
    print("  4. âœ… æ–°å¢æ¸©åº¦è¾¾æ ‡ç‡ã€è¶…è°ƒç‡ã€å¹³æ»‘åº¦ç­‰å®ç”¨æŒ‡æ ‡")
    print("  5. âœ… è¯¦ç»†çš„æŒ‡æ ‡è§£é‡Šå’Œå¯è§†åŒ–å‡†å¤‡")

    print("\nğŸ“Š æŒ‡æ ‡è§£é‡Š:")
    print("  â€¢ MAE/RMSE: è¶Šå°è¶Šå¥½ï¼ˆç†æƒ³å€¼ <5Â°Cï¼‰")
    print("  â€¢ æ¸©åº¦è¾¾æ ‡ç‡: è¶Šé«˜è¶Šå¥½ï¼ˆç›®æ ‡ >90%ï¼‰")
    print("  â€¢ æ¸©åº¦æ ‡å‡†å·®: è¶Šå°è¶Šå¥½ï¼ˆè¡¨ç¤ºæ§åˆ¶ç¨³å®šï¼‰")
    print("  â€¢ è¶…è°ƒç‡: è¶Šä½è¶Šå¥½ï¼ˆé¿å…æ¸©åº¦è¿‡é«˜ï¼‰")
    print("  â€¢ åŠ¨ä½œå¹³æ»‘åº¦: è¶Šå°è¶Šå¥½ï¼ˆé¿å…é¢‘ç¹è°ƒæ•´ï¼‰")

    print("\n" + "=" * 70)
    print("âœ“ è¯„ä¼°æ¨¡å—å‡†å¤‡å°±ç»ª".center(70))
    print("=" * 70)
